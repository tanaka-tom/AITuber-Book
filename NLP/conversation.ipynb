{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow==1.12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FILE_NAME_CONVERSATIONS = \\\n",
    "    \"../input/movie-dialog-corpus/movie_conversations.tsv\"\n",
    "DATASET_COLUMNS_CONVERSATIONS = \\\n",
    "    [\"character1_id\", \"character2_id\", \"movie_id\", \"conversation_list\"]\n",
    "DATASET_FILE_NAME_LINES = \"../input/movie-dialog-corpus/movie_lines.tsv\"\n",
    "DATASET_COLUMNS_LINES = \\\n",
    "    [\"line_id\", \"character_id\", \"movie_id\", \"charcter_name\", \"text\"]\n",
    "DATASET_ENCODING = \"ISO-8859-1\"\n",
    "DATASET_SEPARATOR = \"\\t\"\n",
    "\n",
    "conversations_df = pd.read_csv(\n",
    "    DATASET_FILE_NAME_CONVERSATIONS,\n",
    "    sep=DATASET_SEPARATOR,\n",
    "    encoding=DATASET_ENCODING,\n",
    "    names=DATASET_COLUMNS_CONVERSATIONS,\n",
    "    engine=\"python\")\n",
    "lines_df = pd.read_csv(\n",
    "    DATASET_FILE_NAME_LINES,\n",
    "    sep=DATASET_SEPARATOR,\n",
    "    encoding=DATASET_ENCODING,\n",
    "    names=DATASET_COLUMNS_LINES,\n",
    "    index_col=0,\n",
    "    error_bad_lines=False,\n",
    "    warn_bad_lines=False,\n",
    "    engine=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = re.sub(r\"he's\", \"he is\", text)\n",
    "    text = re.sub(r\"she's\", \"she is\", text)\n",
    "    text = re.sub(r\"it's\", \"it is\", text)\n",
    "    text = re.sub(r\"that's\", \"that is\", text)\n",
    "    text = re.sub(r\"what's\", \"that is\", text)\n",
    "    text = re.sub(r\"where's\", \"where is\", text)\n",
    "    text = re.sub(r\"how's\", \"how is\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"can't\", \"cannot\", text)\n",
    "    text = re.sub(r\"n't\", \" not\", text)\n",
    "    text = re.sub(r\"n'\", \"ng\", text)\n",
    "    text = re.sub(r\"'bout\", \"about\", text)\n",
    "    text = re.sub(r\"'til\", \"until\", text)\n",
    "    text = re.sub(r\"[-()\\\"'#/@;:<>{}`+=~|.!?,]\", \"\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_df.text = lines_df.text.apply(lambda x: clean_text(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 30\n",
    "\n",
    "enc_input = []\n",
    "dec_input = []\n",
    "\n",
    "def convert_str_to_list(s):\n",
    "    s = s.strip(\"['\")\n",
    "    s = s.strip(\"']\")\n",
    "    return s.split(\"' '\")\n",
    "\n",
    "for c_i, row in conversations_df.iterrows():\n",
    "    conversation_list = convert_str_to_list(row.conversation_list)\n",
    "    for i in range(len(conversation_list) - 1):\n",
    "        try:\n",
    "            x_id = conversation_list[i]\n",
    "            y_id = conversation_list[i+1]\n",
    "            x = lines_df.at[x_id, \"text\"]\n",
    "            y = lines_df.at[y_id, \"text\"]\n",
    "            if len(x) > SEQUENCE_LENGTH or len(y) > SEQUENCE_LENGTH:\n",
    "              continue\n",
    "            enc_input.append(\"<s> {} </s>\".format(x))\n",
    "            dec_input.append(\"<s> {} </s>\".format(y))\n",
    "        except KeyError:\n",
    "            # nothing to do\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(filters=\"\")\n",
    "tokenize_texts = enc_input[:] + dec_input[:]\n",
    "tokenizer.fit_on_texts(pd.Series(tokenize_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"seq2seq_tokenizer.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "e = pad_sequences(\n",
    "            tokenizer.texts_to_sequences(enc_input),\n",
    "            padding=\"post\",\n",
    "            maxlen=SEQUENCE_LENGTH)\n",
    "d = pad_sequences(\n",
    "            tokenizer.texts_to_sequences(dec_input),\n",
    "            padding=\"post\",\n",
    "            maxlen=SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_split = int(len(enc_input) * 0.8)\n",
    "e_train,e_test=np.vsplit(e,[n_split])\n",
    "d_train,d_test=np.vsplit(d,[n_split])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = np.hstack(\n",
    "                (d_train[:, 1:], np.zeros((len(d_train), 1),\n",
    "                dtype=np.int32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, LSTM\n",
    "\n",
    "EMBEDDING_DIM = 256\n",
    "HIDDEN_DIM = 256\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "encoder_inputs = Input(shape=(SEQUENCE_LENGTH,))\n",
    "encoder_embedded = Embedding(\n",
    "                    vocab_size,\n",
    "                    EMBEDDING_DIM,\n",
    "                    mask_zero=True)(encoder_inputs)\n",
    "_, *encoder_states = LSTM(HIDDEN_DIM, return_state=True)(encoder_embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "decoder_inputs = Input(shape=(SEQUENCE_LENGTH,))\n",
    "decoder_embedding_layer = Embedding(vocab_size, EMBEDDING_DIM)\n",
    "decoder_embedded = decoder_embedding_layer(decoder_inputs)\n",
    "decoder_lstm_layer = LSTM(HIDDEN_DIM, return_sequences=True, return_state=True)\n",
    "decoder_outputs, *_ = decoder_lstm_layer(\n",
    "                        decoder_embedded,\n",
    "                        initial_state=encoder_states)\n",
    "decoder_dense_layer = Dense(vocab_size, activation=\"softmax\")\n",
    "decoder_outputs = decoder_dense_layer(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_outputs, *_ = decoder_lstm_layer(\n",
    "                        decoder_embedded,\n",
    "                        initial_state=encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"rmsprop\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "plot_model(model, to_file=\"seq2seq_model.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "        [encoder_train, decoder_train],\n",
    "        np.expand_dims(target_train, -1),\n",
    "        batch_size=128,\n",
    "        epochs=15,\n",
    "        verbose=2,\n",
    "        validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"seq2seq.h5\")\n",
    "print(\"model saved as seq2seq.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_inputs = Input(shape=(1,))\n",
    "decoder_embedded = decoder_embedding_layer(decoder_inputs)\n",
    "decoder_states_inputs = [\n",
    "                Input(shape=(HIDDEN_DIM,)),\n",
    "                Input(shape=(HIDDEN_DIM,))]\n",
    "decoder_lstm, *decoder_states = decoder_lstm_layer(\n",
    "                                    decoder_embedded,\n",
    "                                    initial_state=decoder_states_inputs)\n",
    "decoder_outputs = decoder_dense_layer(decoder_lstm)\n",
    "decoder_model = Model(\n",
    "                    [decoder_inputs] + decoder_states_inputs,\n",
    "                    [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index = tokenizer.word_index\n",
    "index2word = dict(map(reversed, word2index.items()))\n",
    "bos = [word2index[\"<s>\"]]\n",
    "eos = [word2index[\"</s>\"]]\n",
    "\n",
    "MAX_OUTPUT_LENGTH = 100\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    formated_input_seq = \"<s> {} </s>\".format(clean_text(input_seq))\n",
    "    tokenized_input_seq = pad_sequences(\n",
    "        tokenizer.texts_to_sequences([formated_input_seq]),\n",
    "        padding=\"post\",\n",
    "        maxlen=max_seq_len)\n",
    "\n",
    "    states = encoder_model.predict(tokenized_input_seq)\n",
    "\n",
    "    target = np.array(bos)\n",
    "    output_seq = bos\n",
    "\n",
    "    for i in range(MAX_OUTPUT_LENGTH):\n",
    "        tokens, *states = decoder_model.predict([target] + states)\n",
    "        output_index = [np.argmax(tokens[0, -1, :])]\n",
    "        output_seq += output_index\n",
    "        if output_index == eos:\n",
    "            break\n",
    "        target = np.array(output_index)\n",
    "\n",
    "    output_seq = \"　\".join([index2word[i]\n",
    "                       for i in output_seq if i not in bos + eos])\n",
    "    return output_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seq = \"How are you?\"\n",
    "print(decode_sequence(input_seq))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
